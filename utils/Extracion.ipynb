{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d3e166",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'except' or 'finally' block (2220622611.py, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 69\u001b[1;36m\u001b[0m\n\u001b[1;33m    def get_categories(tenant_id,token):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected 'except' or 'finally' block\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# El resto del c√≥digo se mantiene igual\n",
    "# Configuraci√≥n de VALD\n",
    "CLIENT_ID = \"Nr37673W7ncT4qBQ==\"\n",
    "CLIENT_SECRET = \"EMiYKddb7wKrwgxxLqopECDpkNLiS1XOEaw=\"\n",
    "# TENANT_ID = \"f1185650-fb79-44a0-8b4b-b2bf82d28c83\"\n",
    "FECHA_DESDE = \"2023-01-01T00:00:00.000Z\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "token = ''\n",
    "# URL para solicitar el token\n",
    "token_url = \"https://security.valdperformance.com/connect/token\"\n",
    "\n",
    "# Datos para la solicitud del token\n",
    "payload = {\n",
    "    \"grant_type\": \"client_credentials\",\n",
    "    \"client_id\": CLIENT_ID,\n",
    "    \"client_secret\": CLIENT_SECRET\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Realizar la solicitud\n",
    "    response = requests.post(token_url, data=payload)\n",
    "    \n",
    "    # Verificar respuesta\n",
    "    if response.status_code == 200:\n",
    "        token_data = response.json()\n",
    "        print(token_data)\n",
    "        print(\"‚úÖ Autenticaci√≥n exitosa\")\n",
    "        token = token_data.get('access_token')\n",
    "    else:\n",
    "        print(f\"‚ùå Error en la autenticaci√≥n: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error inesperado: {str(e)}\")\n",
    "   \n",
    "   \n",
    "   \n",
    "tenant_id=''\n",
    "# URL CORRECTA (la misma del cURL que funciona)\n",
    "url = \"https://prd-aue-api-externaltenants.valdperformance.com/tenants\"\n",
    "\n",
    "# Headers exactamente como en el cURL\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "try:\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_categories(tenant_id,token):\n",
    "    # URL base y endpoint\n",
    "    url = \"https://prd-aue-api-externaltenants.valdperformance.com/categories\"\n",
    "\n",
    "    # Headers con token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Par√°metros\n",
    "    params = {\n",
    "        \"TenantId\": tenant_id\n",
    "    }\n",
    "\n",
    "    # Realizar la solicitud\n",
    "    print(\"üîÑ Solicitando categories a la API...\")\n",
    "    response_categories = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    # Decodificar y parsear JSON\n",
    "    categories = json.loads(response_categories.content.decode('utf-8'))\n",
    "\n",
    "    # 2. Crear DataFrame directamente\n",
    "    df_categories_ = pd.DataFrame(categories['categories'])\n",
    "\n",
    "    df_categories_['tenant_id'] = tenant_id\n",
    "\n",
    "    return df_categories_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_groups(tenant_id,token):\n",
    "    # URL base y endpoint\n",
    "    url = \"https://prd-aue-api-externaltenants.valdperformance.com/groups\"\n",
    "\n",
    "    # Headers con token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Par√°metros\n",
    "    params = {\n",
    "        \"TenantId\": tenant_id\n",
    "    }\n",
    "\n",
    "    # Realizar la solicitud\n",
    "    print(\"üîÑ Solicitando grupos a la API...\")\n",
    "    response_groups = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    # Decodificar y parsear JSON\n",
    "    groups = json.loads(response_groups.content.decode('utf-8'))\n",
    "\n",
    "    # 2. Crear DataFrame directamente\n",
    "    df_groups_ = pd.DataFrame(groups['groups'])\n",
    "\n",
    "    df_groups_['tenant_id'] = tenant_id\n",
    "\n",
    "    return df_groups_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Suponiendo que tus DataFrames se llaman df_categories y df_groups\n",
    "# Hacer el merge usando el id de categor√≠a\n",
    "df_groups_with_category = df_groups.merge(\n",
    "    df_categories[['id', 'name']], \n",
    "    left_on='categoryId', \n",
    "    right_on='id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renombrar la columna 'name' que viene de categor√≠as para que sea m√°s clara\n",
    "df_groups_with_category = df_groups_with_category.rename(columns={'name_y': 'category_name', 'name_x': 'group_name'})\n",
    "\n",
    "# O si prefieres ser m√°s espec√≠fico desde el merge:\n",
    "df_groups_with_category = df_groups.merge(\n",
    "    df_categories[['id', 'name']].rename(columns={'name': 'category_name'}), \n",
    "    left_on='categoryId', \n",
    "    right_on='id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Eliminar la columna 'id' duplicada del merge\n",
    "df_groups_with_category = df_groups_with_category.drop(columns=['id_y'])\n",
    "df_groups_with_category = df_groups_with_category.rename(columns={'id_x': 'id'})\n",
    "df_groups_with_category\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_profiles(token, tenant_id, groupId, groupName, categoryId, categoryName):\n",
    "    # URL base y endpoint\n",
    "    url = \"https://prd-aue-api-externalprofile.valdperformance.com/profiles\"\n",
    "\n",
    "    # Headers con token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Par√°metros\n",
    "    params = {\n",
    "        \"TenantId\": tenant_id,\n",
    "        \"groupId\": groupId\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Realizar la solicitud\n",
    "        print(\"üîÑ Solicitando perfiles a la API...\")\n",
    "        response_profiles = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        # Verificar el status code\n",
    "        if response_profiles.status_code != 200:\n",
    "            print(f\"‚ö†Ô∏è Error HTTP {response_profiles.status_code} para grupo {groupName}\")\n",
    "            return pd.DataFrame()  # Retorna DataFrame vac√≠o\n",
    "        \n",
    "        # Verificar si hay contenido\n",
    "        if not response_profiles.content or response_profiles.content == b'':\n",
    "            print(f\"‚ö†Ô∏è Respuesta vac√≠a para grupo {groupName}\")\n",
    "            return pd.DataFrame()  # Retorna DataFrame vac√≠o\n",
    "        \n",
    "        # Decodificar y parsear JSON\n",
    "        content_str = response_profiles.content.decode('utf-8')\n",
    "        \n",
    "        # Verificar que no sea una cadena vac√≠a\n",
    "        if not content_str.strip():\n",
    "            print(f\"‚ö†Ô∏è Contenido vac√≠o para grupo {groupName}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        profiles = json.loads(content_str)\n",
    "        \n",
    "        # Verificar que tenga la estructura esperada\n",
    "        if 'profiles' not in profiles:\n",
    "            print(f\"‚ö†Ô∏è Estructura JSON inesperada para grupo {groupName}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Verificar que profiles no est√© vac√≠o\n",
    "        if not profiles['profiles']:\n",
    "            print(f\"‚ÑπÔ∏è No hay perfiles para el grupo {groupName}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Crear DataFrame\n",
    "        df_profiles_ = pd.DataFrame(profiles['profiles'])\n",
    "        \n",
    "        # Agregar informaci√≥n del grupo\n",
    "        df_profiles_['tenant_id'] = tenant_id\n",
    "        df_profiles_['groupId'] = groupId\n",
    "        df_profiles_['groupName'] = groupName\n",
    "        df_profiles_['categoryId'] = categoryId\n",
    "        df_profiles_['categoryName'] = categoryName\n",
    "        \n",
    "        print(f\"‚úÖ {len(df_profiles_)} perfiles obtenidos para {groupName}\")\n",
    "        return df_profiles_\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå Error JSON para grupo {groupName}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inesperado para grupo {groupName}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Recorrer df_groups_with_category\n",
    "df_profiles = pd.DataFrame()\n",
    "successful_requests = 0\n",
    "failed_requests = 0\n",
    "\n",
    "for index, row in df_groups_with_category.iterrows():\n",
    "    print(f\"\\nProcesando grupo {index+1}/{len(df_groups_with_category)}: {row['id']}, {row['name']}...\")\n",
    "    \n",
    "    df_profiles_ = get_profiles(token, row['tenant_id'], row['id'], \n",
    "                              row['name'], row['categoryId'], row['category_name'])\n",
    "    \n",
    "    if not df_profiles_.empty:\n",
    "        df_profiles = pd.concat([df_profiles, df_profiles_], ignore_index=True)\n",
    "        successful_requests += 1\n",
    "    else:\n",
    "        failed_requests += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_nordbord(token, tenant_id, fecha_desde):\n",
    "    \"\"\"Obtiene los datos de pruebas desde la API de VALD\"\"\"\n",
    "    \n",
    "    # URL base seg√∫n regi√≥n\n",
    "    base_url = \"https://prd-aue-api-externalnordbord.valdperformance.com\"\n",
    "    \n",
    "    # Endpoint y par√°metros\n",
    "    endpoint = \"/tests/v2\"\n",
    "    params = {\n",
    "        \"tenantId\": tenant_id,\n",
    "        \"modifiedFromUtc\": fecha_desde\n",
    "    }\n",
    "    \n",
    "    # Headers con token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    # Realizar la solicitud\n",
    "    print(\"üîÑ Solicitando datos a la API...\")\n",
    "    response = requests.get(f\"{base_url}{endpoint}\", params=params, headers=headers)\n",
    "    \n",
    "    # Verificar respuesta\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ Datos obtenidos correctamente\")\n",
    "        datos = response.json()\n",
    "    \n",
    "        # Verificar tipo de datos y normalizarlos\n",
    "        if isinstance(datos, dict) and 'items' in datos:\n",
    "            df = pd.DataFrame(datos['items'])\n",
    "        elif isinstance(datos, list):\n",
    "            df = pd.DataFrame(datos)\n",
    "        else:\n",
    "            df = pd.DataFrame([datos])\n",
    "        \n",
    "        # Si existe la columna 'tests' y contiene datos, normalizarla\n",
    "        if 'tests' in df.columns and len(df) > 0 and isinstance(df['tests'].iloc[0], (list, dict)):\n",
    "            try:\n",
    "                # Normalizar la columna tests\n",
    "                expanded_df = pd.json_normalize(df['tests'].iloc[0])\n",
    "                \n",
    "                # Convertir columnas de fecha a datetime\n",
    "                date_columns = [col for col in expanded_df.columns \n",
    "                                if 'date' in col.lower() or 'time' in col.lower()]\n",
    "                for col in date_columns:\n",
    "                    expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n",
    "                \n",
    "                # Reemplazar el DataFrame original con el normalizado\n",
    "                df = expanded_df\n",
    "                print(\"‚úÖ Normalizaci√≥n aplicada a la columna 'tests'\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è No se pudo normalizar la columna 'tests': {e}\")\n",
    "        return df\n",
    "    elif response.status_code == 204:\n",
    "        print(\"‚ö†Ô∏è No hay m√°s registros para obtener.\")\n",
    "        return []\n",
    "    else:\n",
    "        print(f\"‚ùå Error al obtener datos: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recorrer df_groups_with_category\n",
    "#get_nordbord(token, tenant_id, fecha_desde):\n",
    "df_tests_nordbord = pd.DataFrame()\n",
    "successful_requests = 0\n",
    "failed_requests = 0\n",
    "desde = \"2023-01-01T00:00:00.000Z\"\n",
    "\n",
    "for index, row in df_tenants.iterrows():\n",
    "    \n",
    "    df_tests_nordbord_ = get_nordbord(token, row['id'], desde)\n",
    "    \n",
    "    if not df_tests_nordbord_.empty:\n",
    "        df_tests_nordbord = pd.concat([df_tests_nordbord, df_tests_nordbord_], ignore_index=True)\n",
    "        successful_requests += 1\n",
    "    else:\n",
    "        failed_requests += 1\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "def get_ForceFrame(token, tenant_id, fecha_desde):\n",
    "    \"\"\"Obtiene los datos de pruebas desde la API de VALD\"\"\"\n",
    "    \n",
    "    # URL base seg√∫n regi√≥n\n",
    "    base_url = \"https://prd-aue-api-externalforceframe.valdperformance.com/\"\n",
    "    \n",
    "    # Endpoint y par√°metros\n",
    "    endpoint = \"/tests/v2\"\n",
    "    params = {\n",
    "        \"tenantId\": tenant_id,\n",
    "        \"modifiedFromUtc\": fecha_desde\n",
    "    }\n",
    "    \n",
    "    # Headers con token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    # Realizar la solicitud\n",
    "    print(\"üîÑ Solicitando datos a la API...\")\n",
    "    response = requests.get(f\"{base_url}{endpoint}\", params=params, headers=headers)\n",
    "    \n",
    "    # Verificar respuesta\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ Datos obtenidos correctamente\")\n",
    "        datos = response.json()\n",
    "    \n",
    "        # Verificar tipo de datos y normalizarlos\n",
    "        if isinstance(datos, dict) and 'items' in datos:\n",
    "            df = pd.DataFrame(datos['items'])\n",
    "        elif isinstance(datos, list):\n",
    "            df = pd.DataFrame(datos)\n",
    "        else:\n",
    "            df = pd.DataFrame([datos])\n",
    "        \n",
    "        # Si existe la columna 'tests' y contiene datos, normalizarla\n",
    "        if 'tests' in df.columns and len(df) > 0 and isinstance(df['tests'].iloc[0], (list, dict)):\n",
    "            try:\n",
    "                # Normalizar la columna tests\n",
    "                expanded_df = pd.json_normalize(df['tests'].iloc[0])\n",
    "                \n",
    "                # Convertir columnas de fecha a datetime\n",
    "                date_columns = [col for col in expanded_df.columns \n",
    "                                if 'date' in col.lower() or 'time' in col.lower()]\n",
    "                for col in date_columns:\n",
    "                    expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n",
    "                \n",
    "                # Reemplazar el DataFrame original con el normalizado\n",
    "                df = expanded_df\n",
    "                print(\"‚úÖ Normalizaci√≥n aplicada a la columna 'tests'\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è No se pudo normalizar la columna 'tests': {e}\")\n",
    "        return df\n",
    "    elif response.status_code == 204:\n",
    "        print(\"‚ö†Ô∏è No hay m√°s registros para obtener.\")\n",
    "        return []\n",
    "    else:\n",
    "        print(f\"‚ùå Error al obtener datos: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "df_tests_ForceFrame = pd.DataFrame()\n",
    "successful_requests = 0\n",
    "failed_requests = 0\n",
    "desde = \"2023-01-01T00:00:00.000Z\"\n",
    "\n",
    "for index, row in df_tenants.iterrows():\n",
    "    \n",
    "    df_tests_ForceFrame_ = get_ForceFrame(token, row['id'], desde)\n",
    "\n",
    "    if not df_tests_ForceFrame_.empty:\n",
    "        df_tests_ForceFrame = pd.concat([df_tests_ForceFrame, df_tests_ForceFrame_], ignore_index=True)\n",
    "        successful_requests += 1\n",
    "    else:\n",
    "        failed_requests += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf1bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Autenticaci√≥n exitosa\n",
      "‚úÖ Datos de tenants guardados en output_data\\tenants.csv\n",
      "\n",
      "üîç Procesando tenant 1/1: STAFF - Luciano Tomagheli\n",
      "üîÑ Solicitando categories a la API...\n",
      "‚úÖ Categor√≠as para tenant f1185650-fb79-44a0-8b4b-b2bf82d28c83 guardadas en output_data\\categories_f1185650-fb79-44a0-8b4b-b2bf82d28c83.csv\n",
      "üîÑ Solicitando grupos a la API...\n",
      "‚úÖ Grupos para tenant f1185650-fb79-44a0-8b4b-b2bf82d28c83 guardados en output_data\\groups_f1185650-fb79-44a0-8b4b-b2bf82d28c83.csv\n",
      "‚úÖ Grupos con categor√≠as guardados en output_data\\groups_with_categories_f1185650-fb79-44a0-8b4b-b2bf82d28c83.csv\n",
      "\n",
      "üìä Obteniendo perfiles para cada grupo...\n",
      "üîÑ Solicitando perfiles para grupo 1...\n",
      "‚úÖ 30 perfiles obtenidos para grupo 1\n",
      "üîÑ Solicitando perfiles para grupo 2...\n",
      "‚úÖ 30 perfiles obtenidos para grupo 2\n",
      "üîÑ Solicitando perfiles para grupo 3...\n",
      "‚úÖ 28 perfiles obtenidos para grupo 3\n",
      "üîÑ Solicitando perfiles para grupo 4...\n",
      "‚úÖ 30 perfiles obtenidos para grupo 4\n",
      "üîÑ Solicitando perfiles para grupo 4ta...\n",
      "‚úÖ 39 perfiles obtenidos para grupo 4ta\n",
      "üîÑ Solicitando perfiles para grupo 5ta...\n",
      "‚úÖ 30 perfiles obtenidos para grupo 5ta\n",
      "üîÑ Solicitando perfiles para grupo 6ta...\n",
      "‚úÖ 29 perfiles obtenidos para grupo 6ta\n",
      "üîÑ Solicitando perfiles para grupo ACL...\n",
      "‚úÖ 12 perfiles obtenidos para grupo ACL\n",
      "üîÑ Solicitando perfiles para grupo ACL...\n",
      "‚úÖ 15 perfiles obtenidos para grupo ACL\n",
      "üîÑ Solicitando perfiles para grupo Agile...\n",
      "‚úÖ 2 perfiles obtenidos para grupo Agile\n",
      "üîÑ Solicitando perfiles para grupo Apertura...\n",
      "‚úÖ 6 perfiles obtenidos para grupo Apertura\n",
      "üîÑ Solicitando perfiles para grupo Archive - Dario Sarmiento.fda - 2024.07.29 09.42.12...\n",
      "‚úÖ 1 perfiles obtenidos para grupo Archive - Dario Sarmiento.fda - 2024.07.29 09.42.12\n",
      "üîÑ Solicitando perfiles para grupo Armador...\n",
      "‚úÖ 3 perfiles obtenidos para grupo Armador\n",
      "üîÑ Solicitando perfiles para grupo Arsenal...\n",
      "‚úÖ 46 perfiles obtenidos para grupo Arsenal\n",
      "üîÑ Solicitando perfiles para grupo BAC...\n",
      "‚úÖ 35 perfiles obtenidos para grupo BAC\n",
      "üîÑ Solicitando perfiles para grupo Banco Provincia Seleccion Verde...\n",
      "‚úÖ 7 perfiles obtenidos para grupo Banco Provincia Seleccion Verde\n",
      "üîÑ Solicitando perfiles para grupo Baseball...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Baseball\n",
      "üîÑ Solicitando perfiles para grupo CAH Femenino...\n",
      "‚úÖ 29 perfiles obtenidos para grupo CAH Femenino\n",
      "üîÑ Solicitando perfiles para grupo CAH Huracan...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo CAH Huracan\n",
      "üîÑ Solicitando perfiles para grupo CAH Novena...\n",
      "‚úÖ 23 perfiles obtenidos para grupo CAH Novena\n",
      "üîÑ Solicitando perfiles para grupo CAH Octava...\n",
      "‚úÖ 39 perfiles obtenidos para grupo CAH Octava\n",
      "üîÑ Solicitando perfiles para grupo CAH Septima...\n",
      "‚úÖ 14 perfiles obtenidos para grupo CAH Septima\n",
      "üîÑ Solicitando perfiles para grupo CASI hockey femenino...\n",
      "‚úÖ 29 perfiles obtenidos para grupo CASI hockey femenino\n",
      "üîÑ Solicitando perfiles para grupo CASI Primera A...\n",
      "‚úÖ 31 perfiles obtenidos para grupo CASI Primera A\n",
      "üîÑ Solicitando perfiles para grupo CBMM...\n",
      "‚úÖ 32 perfiles obtenidos para grupo CBMM\n",
      "üîÑ Solicitando perfiles para grupo Central...\n",
      "‚úÖ 5 perfiles obtenidos para grupo Central\n",
      "üîÑ Solicitando perfiles para grupo Centro...\n",
      "‚úÖ 13 perfiles obtenidos para grupo Centro\n",
      "üîÑ Solicitando perfiles para grupo Champa...\n",
      "‚úÖ 19 perfiles obtenidos para grupo Champa\n",
      "üîÑ Solicitando perfiles para grupo Ciudad Division de Honor...\n",
      "‚úÖ 20 perfiles obtenidos para grupo Ciudad Division de Honor\n",
      "üîÑ Solicitando perfiles para grupo Conmocion...\n",
      "‚úÖ 7 perfiles obtenidos para grupo Conmocion\n",
      "üîÑ Solicitando perfiles para grupo Curso...\n",
      "‚úÖ 4 perfiles obtenidos para grupo Curso\n",
      "üîÑ Solicitando perfiles para grupo Defensa...\n",
      "‚úÖ 37 perfiles obtenidos para grupo Defensa\n",
      "üîÑ Solicitando perfiles para grupo DS...\n",
      "‚úÖ 3 perfiles obtenidos para grupo DS\n",
      "üîÑ Solicitando perfiles para grupo Dynamo...\n",
      "‚úÖ 1 perfiles obtenidos para grupo Dynamo\n",
      "üîÑ Solicitando perfiles para grupo Female team...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Female team\n",
      "üîÑ Solicitando perfiles para grupo Femenil Mayor...\n",
      "‚úÖ 1 perfiles obtenidos para grupo Femenil Mayor\n",
      "üîÑ Solicitando perfiles para grupo Fullback...\n",
      "‚úÖ 9 perfiles obtenidos para grupo Fullback\n",
      "üîÑ Solicitando perfiles para grupo Futbol...\n",
      "‚úÖ 7 perfiles obtenidos para grupo Futbol\n",
      "üîÑ Solicitando perfiles para grupo General...\n",
      "‚úÖ 12 perfiles obtenidos para grupo General\n",
      "üîÑ Solicitando perfiles para grupo Georgia's Tests...\n",
      "‚úÖ 6 perfiles obtenidos para grupo Georgia's Tests\n",
      "üîÑ Solicitando perfiles para grupo Godoy Cruz 4ta...\n",
      "‚úÖ 21 perfiles obtenidos para grupo Godoy Cruz 4ta\n",
      "üîÑ Solicitando perfiles para grupo Handball Masculino...\n",
      "‚úÖ 22 perfiles obtenidos para grupo Handball Masculino\n",
      "üîÑ Solicitando perfiles para grupo Hooker...\n",
      "‚úÖ 5 perfiles obtenidos para grupo Hooker\n",
      "üîÑ Solicitando perfiles para grupo Hurling...\n",
      "‚úÖ 17 perfiles obtenidos para grupo Hurling\n",
      "üîÑ Solicitando perfiles para grupo Inactivos...\n",
      "‚úÖ 4 perfiles obtenidos para grupo Inactivos\n",
      "üîÑ Solicitando perfiles para grupo Inferiores Huracan...\n",
      "‚úÖ 65 perfiles obtenidos para grupo Inferiores Huracan\n",
      "üîÑ Solicitando perfiles para grupo Isquiotibial...\n",
      "‚úÖ 22 perfiles obtenidos para grupo Isquiotibial\n",
      "üîÑ Solicitando perfiles para grupo Isquiotibiales...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Isquiotibiales\n",
      "üîÑ Solicitando perfiles para grupo Jugadores Lesionados...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Jugadores Lesionados\n",
      "üîÑ Solicitando perfiles para grupo Leones...\n",
      "‚úÖ 29 perfiles obtenidos para grupo Leones\n",
      "üîÑ Solicitando perfiles para grupo Libero...\n",
      "‚úÖ 2 perfiles obtenidos para grupo Libero\n",
      "üîÑ Solicitando perfiles para grupo LMRC...\n",
      "‚úÖ 19 perfiles obtenidos para grupo LMRC\n",
      "üîÑ Solicitando perfiles para grupo Loans...\n",
      "‚úÖ 1 perfiles obtenidos para grupo Loans\n",
      "üîÑ Solicitando perfiles para grupo M15 2025...\n",
      "‚úÖ 37 perfiles obtenidos para grupo M15 2025\n",
      "üîÑ Solicitando perfiles para grupo M16 2025...\n",
      "‚úÖ 35 perfiles obtenidos para grupo M16 2025\n",
      "üîÑ Solicitando perfiles para grupo M17 2025...\n",
      "‚úÖ 52 perfiles obtenidos para grupo M17 2025\n",
      "üîÑ Solicitando perfiles para grupo M19 2025...\n",
      "‚úÖ 68 perfiles obtenidos para grupo M19 2025\n",
      "üîÑ Solicitando perfiles para grupo Male team...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Male team\n",
      "üîÑ Solicitando perfiles para grupo Medio Scrum...\n",
      "‚úÖ 6 perfiles obtenidos para grupo Medio Scrum\n",
      "üîÑ Solicitando perfiles para grupo Migration...\n",
      "‚úÖ 31 perfiles obtenidos para grupo Migration\n",
      "üîÑ Solicitando perfiles para grupo Miramar Polo ...\n",
      "‚úÖ 6 perfiles obtenidos para grupo Miramar Polo \n",
      "üîÑ Solicitando perfiles para grupo No...\n",
      "‚úÖ 42 perfiles obtenidos para grupo No\n",
      "üîÑ Solicitando perfiles para grupo Obras...\n",
      "‚úÖ 12 perfiles obtenidos para grupo Obras\n",
      "üîÑ Solicitando perfiles para grupo Octavo...\n",
      "‚úÖ 6 perfiles obtenidos para grupo Octavo\n",
      "üîÑ Solicitando perfiles para grupo Olivos RC...\n",
      "‚úÖ 32 perfiles obtenidos para grupo Olivos RC\n",
      "üîÑ Solicitando perfiles para grupo Opuesto...\n",
      "‚úÖ 2 perfiles obtenidos para grupo Opuesto\n",
      "üîÑ Solicitando perfiles para grupo Pala...\n",
      "‚úÖ 20 perfiles obtenidos para grupo Pala\n",
      "üîÑ Solicitando perfiles para grupo Pilar Derecho...\n",
      "‚úÖ 8 perfiles obtenidos para grupo Pilar Derecho\n",
      "üîÑ Solicitando perfiles para grupo Pilar Izquierdo...\n",
      "‚úÖ 9 perfiles obtenidos para grupo Pilar Izquierdo\n",
      "üîÑ Solicitando perfiles para grupo Plantel Profesional...\n",
      "‚úÖ 1 perfiles obtenidos para grupo Plantel Profesional\n",
      "üîÑ Solicitando perfiles para grupo Plantel Superior...\n",
      "‚úÖ 168 perfiles obtenidos para grupo Plantel Superior\n",
      "üîÑ Solicitando perfiles para grupo Primer Equipo...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Primer Equipo\n",
      "üîÑ Solicitando perfiles para grupo Primera...\n",
      "‚úÖ 30 perfiles obtenidos para grupo Primera\n",
      "üîÑ Solicitando perfiles para grupo Puey...\n",
      "‚úÖ 32 perfiles obtenidos para grupo Puey\n",
      "üîÑ Solicitando perfiles para grupo Punta...\n",
      "‚úÖ 7 perfiles obtenidos para grupo Punta\n",
      "üîÑ Solicitando perfiles para grupo RCLM...\n",
      "‚úÖ 41 perfiles obtenidos para grupo RCLM\n",
      "üîÑ Solicitando perfiles para grupo Reserva CAH...\n",
      "‚úÖ 17 perfiles obtenidos para grupo Reserva CAH\n",
      "üîÑ Solicitando perfiles para grupo River VB...\n",
      "‚úÖ 18 perfiles obtenidos para grupo River VB\n",
      "üîÑ Solicitando perfiles para grupo Rosario Central...\n",
      "‚úÖ 6 perfiles obtenidos para grupo Rosario Central\n",
      "üîÑ Solicitando perfiles para grupo Rugby...\n",
      "‚úÖ 1 perfiles obtenidos para grupo Rugby\n",
      "üîÑ Solicitando perfiles para grupo San Miguel...\n",
      "‚úÖ 4 perfiles obtenidos para grupo San Miguel\n",
      "üîÑ Solicitando perfiles para grupo SanPa...\n",
      "‚úÖ 22 perfiles obtenidos para grupo SanPa\n",
      "üîÑ Solicitando perfiles para grupo Santa Barbara Femenino...\n",
      "‚úÖ 30 perfiles obtenidos para grupo Santa Barbara Femenino\n",
      "üîÑ Solicitando perfiles para grupo Segunda Linea...\n",
      "‚úÖ 8 perfiles obtenidos para grupo Segunda Linea\n",
      "üîÑ Solicitando perfiles para grupo Sesion 1...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Sesion 1\n",
      "üîÑ Solicitando perfiles para grupo Sub 20...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Sub 20\n",
      "üîÑ Solicitando perfiles para grupo Sub 23...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Sub 23\n",
      "üîÑ Solicitando perfiles para grupo Sub17...\n",
      "‚úÖ 1 perfiles obtenidos para grupo Sub17\n",
      "üîÑ Solicitando perfiles para grupo Sup. Mariano Moreno...\n",
      "‚úÖ 32 perfiles obtenidos para grupo Sup. Mariano Moreno\n",
      "üîÑ Solicitando perfiles para grupo Tenis...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Tenis\n",
      "üîÑ Solicitando perfiles para grupo Tercera Linea...\n",
      "‚úÖ 22 perfiles obtenidos para grupo Tercera Linea\n",
      "üîÑ Solicitando perfiles para grupo Test...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo Test\n",
      "üîÑ Solicitando perfiles para grupo Tigre...\n",
      "‚úÖ 35 perfiles obtenidos para grupo Tigre\n",
      "üîÑ Solicitando perfiles para grupo Titulares...\n",
      "‚úÖ 13 perfiles obtenidos para grupo Titulares\n",
      "üîÑ Solicitando perfiles para grupo Training...\n",
      "‚úÖ 3 perfiles obtenidos para grupo Training\n",
      "üîÑ Solicitando perfiles para grupo TSEAS1RO...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo TSEAS1RO\n",
      "üîÑ Solicitando perfiles para grupo TSEAS2D0...\n",
      "‚ö†Ô∏è Error HTTP 204 para grupo TSEAS2D0\n",
      "üîÑ Solicitando perfiles para grupo UAR...\n",
      "‚úÖ 5 perfiles obtenidos para grupo UAR\n",
      "üîÑ Solicitando perfiles para grupo UAR Juveniles...\n",
      "‚úÖ 55 perfiles obtenidos para grupo UAR Juveniles\n",
      "üîÑ Solicitando perfiles para grupo Velez 4ta...\n",
      "‚úÖ 33 perfiles obtenidos para grupo Velez 4ta\n",
      "üîÑ Solicitando perfiles para grupo Velez 5ta...\n",
      "‚úÖ 30 perfiles obtenidos para grupo Velez 5ta\n",
      "üîÑ Solicitando perfiles para grupo Velez 6ta...\n",
      "‚úÖ 33 perfiles obtenidos para grupo Velez 6ta\n",
      "üîÑ Solicitando perfiles para grupo Velez 7ma...\n",
      "‚úÖ 39 perfiles obtenidos para grupo Velez 7ma\n",
      "üîÑ Solicitando perfiles para grupo Velez 8va...\n",
      "‚úÖ 37 perfiles obtenidos para grupo Velez 8va\n",
      "üîÑ Solicitando perfiles para grupo Velez 9na...\n",
      "‚úÖ 43 perfiles obtenidos para grupo Velez 9na\n",
      "üîÑ Solicitando perfiles para grupo Wing...\n",
      "‚úÖ 4 perfiles obtenidos para grupo Wing\n",
      "üîÑ Solicitando perfiles para grupo Yes...\n",
      "‚úÖ 47 perfiles obtenidos para grupo Yes\n",
      "\n",
      "üìä Obteniendo datos de NordBord...\n",
      "üîÑ Solicitando datos NordBord para tenant f1185650-fb79-44a0-8b4b-b2bf82d28c83...\n",
      "‚úÖ Datos obtenidos correctamente\n",
      "‚úÖ Normalizaci√≥n aplicada a la columna 'tests'\n",
      "‚úÖ Datos NordBord para tenant f1185650-fb79-44a0-8b4b-b2bf82d28c83 guardados en output_data\\nordbord_f1185650-fb79-44a0-8b4b-b2bf82d28c83.csv\n",
      "\n",
      "üìä Obteniendo datos de ForceFrame...\n",
      "üîÑ Solicitando datos ForceFrame para tenant f1185650-fb79-44a0-8b4b-b2bf82d28c83...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1088\\2566829462.py:250: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1088\\2566829462.py:250: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos obtenidos correctamente\n",
      "‚úÖ Normalizaci√≥n aplicada a la columna 'tests'\n",
      "‚úÖ Datos ForceFrame para tenant f1185650-fb79-44a0-8b4b-b2bf82d28c83 guardados en output_data\\forceframe_f1185650-fb79-44a0-8b4b-b2bf82d28c83.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1088\\2566829462.py:313: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_1088\\2566829462.py:313: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuraci√≥n de VALD\n",
    "CLIENT_ID = \"Nr37673W7ncT4qBQ==\"\n",
    "CLIENT_SECRET = \"EMiYKddb7wKrwgxxLqopECDpkNLiS1XOEaw=\"\n",
    "FECHA_DESDE = \"2023-01-01T00:00:00.000Z\"\n",
    "\n",
    "# Crear directorio para guardar los CSV si no existe\n",
    "OUTPUT_DIR = \"output_data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Funci√≥n para obtener token\n",
    "def get_token():\n",
    "    token_url = \"https://security.valdperformance.com/connect/token\"\n",
    "    \n",
    "    payload = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"client_secret\": CLIENT_SECRET\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(token_url, data=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            token_data = response.json()\n",
    "            print(\"‚úÖ Autenticaci√≥n exitosa\")\n",
    "            return token_data.get('access_token')\n",
    "        else:\n",
    "            print(f\"‚ùå Error en la autenticaci√≥n: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inesperado: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Funci√≥n para obtener tenants\n",
    "def get_tenants(token):\n",
    "    url = \"https://prd-aue-api-externaltenants.valdperformance.com/tenants\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            tenants_data = response.json()\n",
    "            df_tenants = pd.DataFrame(tenants_data['tenants'])\n",
    "            \n",
    "            # Guardar a CSV\n",
    "            csv_path = os.path.join(OUTPUT_DIR, \"tenants.csv\")\n",
    "            df_tenants.to_csv(csv_path, index=False)\n",
    "            print(f\"‚úÖ Datos de tenants guardados en {csv_path}\")\n",
    "            \n",
    "            return df_tenants\n",
    "        else:\n",
    "            print(f\"‚ùå Error al obtener tenants: {response.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inesperado: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Funci√≥n para obtener categor√≠as\n",
    "def get_categories(tenant_id, token):\n",
    "    url = \"https://prd-aue-api-externaltenants.valdperformance.com/categories\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"TenantId\": tenant_id\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Solicitando categories a la API...\")\n",
    "        response_categories = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response_categories.status_code != 200:\n",
    "            print(f\"‚ùå Error al obtener categor√≠as: {response_categories.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        categories = json.loads(response_categories.content.decode('utf-8'))\n",
    "        df_categories_ = pd.DataFrame(categories['categories'])\n",
    "        df_categories_['tenant_id'] = tenant_id\n",
    "        \n",
    "        # Guardar a CSV\n",
    "        csv_path = os.path.join(OUTPUT_DIR, f\"categories_{tenant_id}.csv\")\n",
    "        df_categories_.to_csv(csv_path, index=False)\n",
    "        print(f\"‚úÖ Categor√≠as para tenant {tenant_id} guardadas en {csv_path}\")\n",
    "        \n",
    "        return df_categories_\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al obtener categor√≠as: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Funci√≥n para obtener grupos\n",
    "def get_groups(tenant_id, token):\n",
    "    url = \"https://prd-aue-api-externaltenants.valdperformance.com/groups\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"TenantId\": tenant_id\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Solicitando grupos a la API...\")\n",
    "        response_groups = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response_groups.status_code != 200:\n",
    "            print(f\"‚ùå Error al obtener grupos: {response_groups.status_code}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        groups = json.loads(response_groups.content.decode('utf-8'))\n",
    "        df_groups_ = pd.DataFrame(groups['groups'])\n",
    "        df_groups_['tenant_id'] = tenant_id\n",
    "        \n",
    "        # Guardar a CSV\n",
    "        csv_path = os.path.join(OUTPUT_DIR, f\"groups_{tenant_id}.csv\")\n",
    "        df_groups_.to_csv(csv_path, index=False)\n",
    "        print(f\"‚úÖ Grupos para tenant {tenant_id} guardados en {csv_path}\")\n",
    "        \n",
    "        return df_groups_\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al obtener grupos: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Funci√≥n para obtener perfiles\n",
    "# Funci√≥n para obtener perfiles (modificada para un solo CSV)\n",
    "def get_profiles(token, tenant_id, groupId, groupName, categoryId, categoryName, df_all_profiles=None):\n",
    "    url = \"https://prd-aue-api-externalprofile.valdperformance.com/profiles\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"TenantId\": tenant_id,\n",
    "        \"groupId\": groupId\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîÑ Solicitando perfiles para grupo {groupName}...\")\n",
    "        response_profiles = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response_profiles.status_code != 200:\n",
    "            print(f\"‚ö†Ô∏è Error HTTP {response_profiles.status_code} para grupo {groupName}\")\n",
    "            return df_all_profiles if df_all_profiles is not None else pd.DataFrame()\n",
    "        \n",
    "        if not response_profiles.content or response_profiles.content == b'':\n",
    "            print(f\"‚ö†Ô∏è Respuesta vac√≠a para grupo {groupName}\")\n",
    "            return df_all_profiles if df_all_profiles is not None else pd.DataFrame()\n",
    "        \n",
    "        content_str = response_profiles.content.decode('utf-8')\n",
    "        \n",
    "        if not content_str.strip():\n",
    "            print(f\"‚ö†Ô∏è Contenido vac√≠o para grupo {groupName}\")\n",
    "            return df_all_profiles if df_all_profiles is not None else pd.DataFrame()\n",
    "            \n",
    "        profiles = json.loads(content_str)\n",
    "        \n",
    "        if 'profiles' not in profiles:\n",
    "            print(f\"‚ö†Ô∏è Estructura JSON inesperada para grupo {groupName}\")\n",
    "            return df_all_profiles if df_all_profiles is not None else pd.DataFrame()\n",
    "        \n",
    "        if not profiles['profiles']:\n",
    "            print(f\"‚ÑπÔ∏è No hay perfiles para el grupo {groupName}\")\n",
    "            return df_all_profiles if df_all_profiles is not None else pd.DataFrame()\n",
    "        \n",
    "        df_profiles_ = pd.DataFrame(profiles['profiles'])\n",
    "        \n",
    "        df_profiles_['tenant_id'] = tenant_id\n",
    "        df_profiles_['groupId'] = groupId\n",
    "        df_profiles_['groupName'] = groupName\n",
    "        df_profiles_['categoryId'] = categoryId\n",
    "        df_profiles_['categoryName'] = categoryName\n",
    "        \n",
    "        # Si ya tenemos un DataFrame de todos los perfiles, concatenamos\n",
    "        if df_all_profiles is not None:\n",
    "            df_all_profiles = pd.concat([df_all_profiles, df_profiles_], ignore_index=True)\n",
    "        else:\n",
    "            df_all_profiles = df_profiles_\n",
    "        \n",
    "        print(f\"‚úÖ {len(df_profiles_)} perfiles obtenidos para grupo {groupName}\")\n",
    "        \n",
    "        return df_all_profiles\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå Error JSON para grupo {groupName}: {e}\")\n",
    "        return df_all_profiles if df_all_profiles is not None else pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inesperado para grupo {groupName}: {e}\")\n",
    "        return df_all_profiles if df_all_profiles is not None else pd.DataFrame()\n",
    "    \n",
    "\n",
    "# Funci√≥n para obtener datos de NordBord\n",
    "def get_nordbord(token, tenant_id, fecha_desde):\n",
    "    base_url = \"https://prd-aue-api-externalnordbord.valdperformance.com\"\n",
    "    \n",
    "    endpoint = \"/tests/v2\"\n",
    "    params = {\n",
    "        \"tenantId\": tenant_id,\n",
    "        \"modifiedFromUtc\": fecha_desde\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîÑ Solicitando datos NordBord para tenant {tenant_id}...\")\n",
    "        response = requests.get(f\"{base_url}{endpoint}\", params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(f\"‚úÖ Datos obtenidos correctamente\")\n",
    "            datos = response.json()\n",
    "        \n",
    "            if isinstance(datos, dict) and 'items' in datos:\n",
    "                df = pd.DataFrame(datos['items'])\n",
    "            elif isinstance(datos, list):\n",
    "                df = pd.DataFrame(datos)\n",
    "            else:\n",
    "                df = pd.DataFrame([datos])\n",
    "            \n",
    "            if 'tests' in df.columns and len(df) > 0 and isinstance(df['tests'].iloc[0], (list, dict)):\n",
    "                try:\n",
    "                    expanded_df = pd.json_normalize(df['tests'].iloc[0])\n",
    "                    \n",
    "                    date_columns = [col for col in expanded_df.columns \n",
    "                                    if 'date' in col.lower() or 'time' in col.lower()]\n",
    "                    for col in date_columns:\n",
    "                        expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n",
    "                    \n",
    "                    df = expanded_df\n",
    "                    print(\"‚úÖ Normalizaci√≥n aplicada a la columna 'tests'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è No se pudo normalizar la columna 'tests': {e}\")\n",
    "            \n",
    "            # Guardar a CSV\n",
    "            if not df.empty:\n",
    "                csv_path = os.path.join(OUTPUT_DIR, f\"nordbord_{tenant_id}.csv\")\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"‚úÖ Datos NordBord para tenant {tenant_id} guardados en {csv_path}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        elif response.status_code == 204:\n",
    "            print(\"‚ö†Ô∏è No hay m√°s registros para obtener.\")\n",
    "            return pd.DataFrame()\n",
    "        else:\n",
    "            print(f\"‚ùå Error al obtener datos: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al obtener datos NordBord: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Funci√≥n para obtener datos de ForceFrame\n",
    "def get_ForceFrame(token, tenant_id, fecha_desde):\n",
    "    base_url = \"https://prd-aue-api-externalforceframe.valdperformance.com\"\n",
    "    \n",
    "    endpoint = \"/tests/v2\"\n",
    "    params = {\n",
    "        \"tenantId\": tenant_id,\n",
    "        \"modifiedFromUtc\": fecha_desde\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîÑ Solicitando datos ForceFrame para tenant {tenant_id}...\")\n",
    "        response = requests.get(f\"{base_url}{endpoint}\", params=params, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(f\"‚úÖ Datos obtenidos correctamente\")\n",
    "            datos = response.json()\n",
    "        \n",
    "            if isinstance(datos, dict) and 'items' in datos:\n",
    "                df = pd.DataFrame(datos['items'])\n",
    "            elif isinstance(datos, list):\n",
    "                df = pd.DataFrame(datos)\n",
    "            else:\n",
    "                df = pd.DataFrame([datos])\n",
    "            \n",
    "            if 'tests' in df.columns and len(df) > 0 and isinstance(df['tests'].iloc[0], (list, dict)):\n",
    "                try:\n",
    "                    expanded_df = pd.json_normalize(df['tests'].iloc[0])\n",
    "                    \n",
    "                    date_columns = [col for col in expanded_df.columns \n",
    "                                    if 'date' in col.lower() or 'time' in col.lower()]\n",
    "                    for col in date_columns:\n",
    "                        expanded_df[col] = pd.to_datetime(expanded_df[col], errors='ignore')\n",
    "                    \n",
    "                    df = expanded_df\n",
    "                    print(\"‚úÖ Normalizaci√≥n aplicada a la columna 'tests'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è No se pudo normalizar la columna 'tests': {e}\")\n",
    "            \n",
    "            # Guardar a CSV\n",
    "            if not df.empty:\n",
    "                csv_path = os.path.join(OUTPUT_DIR, f\"forceframe_{tenant_id}.csv\")\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"‚úÖ Datos ForceFrame para tenant {tenant_id} guardados en {csv_path}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        elif response.status_code == 204:\n",
    "            print(\"‚ö†Ô∏è No hay m√°s registros para obtener.\")\n",
    "            return pd.DataFrame()\n",
    "        else:\n",
    "            print(f\"‚ùå Error al obtener datos: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al obtener datos ForceFrame: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Funci√≥n principal para ejecutar todo el proceso\n",
    "def run_extraction():\n",
    "    # Obtener token\n",
    "    token = get_token()\n",
    "    if not token:\n",
    "        print(\"‚ùå No se pudo obtener el token. Proceso cancelado.\")\n",
    "        return\n",
    "    \n",
    "    # Obtener tenants\n",
    "    df_tenants = get_tenants(token)\n",
    "    if df_tenants.empty:\n",
    "        print(\"‚ùå No se pudieron obtener los tenants. Proceso cancelado.\")\n",
    "        return\n",
    "    \n",
    "    # Procesar cada tenant\n",
    "    for index, tenant in df_tenants.iterrows():\n",
    "        tenant_id = tenant['id']\n",
    "        tenant_name = tenant['name']\n",
    "        print(f\"\\nüîç Procesando tenant {index+1}/{len(df_tenants)}: {tenant_name}\")\n",
    "        \n",
    "        # Obtener categor√≠as\n",
    "        df_categories = get_categories(tenant_id, token)\n",
    "        \n",
    "        # Obtener grupos\n",
    "        df_groups = get_groups(tenant_id, token)\n",
    "        \n",
    "        # Si hay categor√≠as y grupos, combinarlos\n",
    "        if not df_categories.empty and not df_groups.empty:\n",
    "            # Combinar grupos con categor√≠as\n",
    "            df_groups_with_category = df_groups.merge(\n",
    "                df_categories[['id', 'name']].rename(columns={'name': 'category_name'}),\n",
    "                left_on='categoryId',\n",
    "                right_on='id',\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Limpiar columnas duplicadas\n",
    "            if 'id_y' in df_groups_with_category.columns:\n",
    "                df_groups_with_category = df_groups_with_category.drop(columns=['id_y'])\n",
    "                df_groups_with_category = df_groups_with_category.rename(columns={'id_x': 'id'})\n",
    "            \n",
    "            # Guardar grupos con categor√≠as\n",
    "            csv_path = os.path.join(OUTPUT_DIR, f\"groups_with_categories_{tenant_id}.csv\")\n",
    "            df_groups_with_category.to_csv(csv_path, index=False)\n",
    "            print(f\"‚úÖ Grupos con categor√≠as guardados en {csv_path}\")\n",
    "            \n",
    "            # Obtener perfiles por grupo\n",
    "            print(\"\\nüìä Obteniendo perfiles para cada grupo...\")\n",
    "            for idx, group in df_groups_with_category.iterrows():\n",
    "                get_profiles(\n",
    "                    token, \n",
    "                    tenant_id, \n",
    "                    group['id'], \n",
    "                    group['name'], \n",
    "                    group['categoryId'], \n",
    "                    group.get('category_name', '')\n",
    "                )\n",
    "        \n",
    "        # Obtener datos de NordBord\n",
    "        print(\"\\nüìä Obteniendo datos de NordBord...\")\n",
    "        get_nordbord(token, tenant_id, FECHA_DESDE)\n",
    "        \n",
    "        # Obtener datos de ForceFrame\n",
    "        print(\"\\nüìä Obteniendo datos de ForceFrame...\")\n",
    "        get_ForceFrame(token, tenant_id, FECHA_DESDE)\n",
    "\n",
    "# Ejecutar el proceso completo\n",
    "if __name__ == \"__main__\":\n",
    "    run_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597c853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
